{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab96cd09472b0592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:14:59.176061200Z",
     "start_time": "2024-02-16T06:14:59.161063600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from utils_paragraph import paraphrase_nlp, paraphrasing_predict_llm, paraphrase_initial, \\\n",
    "    paraphrase_seq2lan, recover_lan2seq, paraphrasing_predict_llama\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "\n",
    "openai.api_key = ''\n",
    "openai.api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "\n",
    "from data1.serialize import SerializerSettings\n",
    "from sklearn import metrics\n",
    "from models.darts import get_arima_predictions_data\n",
    "from models.llmtime import get_llmtime_predictions_data\n",
    "from data1.small_context import get_datasets, get_memorization_datasets, get_dataset\n",
    "from models.validation_likelihood_tuning import get_autotuned_predictions_data\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# load_ext autoreload\n",
    "# autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b3a230fb7994d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:14:59.633542200Z",
     "start_time": "2024-02-16T06:14:59.613546900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_preds(train, test, pred_dict, model_name, ds_name, show_samples=False):\n",
    "    pred = pred_dict['median']\n",
    "    pred = pd.Series(pred, index=test.index)\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    plt.plot(train)\n",
    "    plt.plot(test, label='Truth', color='black')\n",
    "    plt.plot(pred, label=model_name, color='purple')\n",
    "    # shade 90% confidence interval\n",
    "    samples = pred_dict['samples']\n",
    "    lower = np.quantile(samples, 0.05, axis=0)\n",
    "    upper = np.quantile(samples, 0.95, axis=0)\n",
    "    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\n",
    "    if show_samples:\n",
    "        samples = pred_dict['samples']\n",
    "        # convert df to numpy array\n",
    "        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\n",
    "        for i in range(min(10, samples.shape[0])):\n",
    "            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\n",
    "    plt.legend(loc='upper left')\n",
    "    if 'NLL/D' in pred_dict:\n",
    "        nll = pred_dict['NLL/D']\n",
    "        if nll is not None:\n",
    "            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes,\n",
    "                     bbox=dict(facecolor='white', alpha=0.5))\n",
    "    plt.savefig(f'{ds_name}{model_name}givenname1.pdf', format='pdf')\n",
    "\n",
    "\n",
    "def plot_preds2(train, test, pred_dict, model_name, ds_name, show_samples=False):\n",
    "    pred = pred_dict['median']\n",
    "    pred = pd.Series(pred, index=test.index)\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    # plt.plot(train)\n",
    "    plt.plot(test, label='Truth', color='black')\n",
    "    plt.plot(pred, label=model_name, color='purple')\n",
    "    # shade 90% confidence interval\n",
    "    samples = pred_dict['samples']\n",
    "    lower = np.quantile(samples, 0.05, axis=0)\n",
    "    upper = np.quantile(samples, 0.95, axis=0)\n",
    "    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\n",
    "    if show_samples:\n",
    "        samples = pred_dict['samples']\n",
    "        # convert df to numpy array\n",
    "        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\n",
    "        for i in range(min(10, samples.shape[0])):\n",
    "            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\n",
    "    plt.legend(loc='upper left')\n",
    "    if 'NLL/D' in pred_dict:\n",
    "        nll = pred_dict['NLL/D']\n",
    "        if nll is not None:\n",
    "            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes,\n",
    "                     bbox=dict(facecolor='white', alpha=0.5))\n",
    "    plt.savefig(f'{ds_name}{model_name}givenname2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167c8b811e892e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:15:00.162580800Z",
     "start_time": "2024-02-16T06:15:00.145581100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_names: ['gpt-3.5-turbo-1106']\n"
     ]
    }
   ],
   "source": [
    "gpt4_hypers = dict(\n",
    "    alpha=0.3,\n",
    "    basic=True,\n",
    "    temp=1.0,\n",
    "    top_p=0.8,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    ")\n",
    "\n",
    "gpt3_hypers = dict(\n",
    "    temp=0.7,\n",
    "    alpha=0.95,\n",
    "    beta=0.3,\n",
    "    basic=False,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\n",
    ")\n",
    "\n",
    "promptcast_hypers = dict(\n",
    "    temp=0.7,\n",
    "    settings=SerializerSettings(base=10, prec=0, signed=True,\n",
    "                                time_sep=', ',\n",
    "                                bit_sep='',\n",
    "                                plus_sign='',\n",
    "                                minus_sign='-',\n",
    "                                half_bin_correction=False,\n",
    "                                decimal_point=''))\n",
    "\n",
    "arima_hypers = dict(p=[12, 30], d=[1, 2], q=[0])\n",
    "\n",
    "model_predict_fns = {\n",
    "    'gpt-3.5-turbo-1106': get_llmtime_predictions_data,\n",
    "    # 'gpt-4-0125-preview': get_llmtime_predictions_data,\n",
    "    # 'llama2-13b-chat': get_llmtime_predictions_data,\n",
    "}\n",
    "\n",
    "model_names = list(model_predict_fns.keys())\n",
    "print(\"Model_names:\", model_names)\n",
    "\n",
    "# Initial out dict\n",
    "\n",
    "datasets_list = [\n",
    "    'AirPassengersDataset',\n",
    "    # 'AusBeerDataset',\n",
    "    # 'GasRateCO2Dataset',\n",
    "    'MonthlyMilkDataset',\n",
    "    'SunspotsDataset',\n",
    "    'WineDataset',\n",
    "    # 'WoolyDataset',\n",
    "    # 'HeartRateDataset',\n",
    "\n",
    "    # 'IstanbulTraffic',\n",
    "    # 'TSMCStock',\n",
    "    # 'TurkeyPower',\n",
    "    # 'ETTh1Dataset',\n",
    "    # 'ETTm2Dataset',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf53bd12360a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:16:30.934974800Z",
     "start_time": "2024-02-16T06:16:03.557229900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  gpt-3.5-turbo-1106\n",
      "dataset_name:  AirPassengersDataset\n",
      "Round:  1\n",
      "Test_lan: 495.0,496.0,497.0,502.0,506.0,511.0,512.0,507.0,511.0,514.0,516.0,518.0,519.0,520.0,521.0,520.0,521.0,522.0,520.0,515.0,514.0,511.0,507.0,505.0,503.0,501.0,502.0,500.0,498.0,497.0,496.0,495.0,496.0,495.0,497.0,495.0,496.0,497.0,499.0,501.0,503.0,505.0,503.0,501.0,503.0,501.0,502.0,503.0,502.0,501.0,503.0,505.0\n",
      "test len: (29,)\n",
      "Seq_pred: (27,)\n",
      "Not enough sequences for prediction\n",
      "\n",
      "\n",
      "MSE: 0.0, MAE: 0.0, MAPE: 0.0, R²: 0.0\n",
      "\n",
      "\n",
      "dataset_name:  MonthlyMilkDataset\n",
      "Round:  1\n",
      "Test_lan: 706.0,724.0,668.0,629.0,675.0,694.0,673.0,751.0,771.0,835.0,807.0,763.0,719.0,680.0,682.0,648.0,692.0,708.0,665.0,767.0,787.0,851.0,822.0,778.0,734.0\n",
      "test len: (34,)\n",
      "Seq_pred: (14,)\n",
      "Not enough sequences for prediction\n",
      "\n",
      "\n",
      "MSE: 0.0, MAE: 0.0, MAPE: 0.0, R²: 0.0\n",
      "\n",
      "\n",
      "dataset_name:  SunspotsDataset\n",
      "Round:  1\n",
      "Test_lan: 57.0, 70.0, 77.0, 64.4, 50.0, 65.8, 69.3, 66.1, 57.0, 68.4, 68.4, 60.3, 58.3, 47.0, 33.9, 50.0, 21.2, 14.4, 33.0, 85.4, 106.8, 98.2, 95.9, 109.7, 89.3, 65.6, 95.7, 99.7, 104.6, 48.7, 77.3, 78.3, 70.0, 73.3, 74.3, 75.3, 96.0, 46.0, 95.3, 67.0, 56.0, 87.0, 48.3, 65.2, 74.1, 71.3, 62.4, 61.6, 68.5, 73.0, 70.0, 55.3, 56.0, 77.0, 53.0, 49.0, 31.8, 63.7, 33.2, 29.4, 14.0, 8.6, 21.3, 37.1, 47.3, 51.2, 53.2, 73.6, 37.6, 73.6, 64.7, 63.1, 77.5, 60.7, 68.4, 63.0, 27.5, 51.4, 45.2, 30.1, 48.6, 43.3, 44.8, 52.1, 24.6, 38.4, 69.2, 93.1, 77.1, 70.0, 156.0, 112.0, 92.3, 132.5, 89.9, 88.1, 127.8, 83.5, 83.5, 71.4, 73.1, 111.1, 68.5, 78.7, 67.0, 54.6, 76.4, 63.5, 65.6, 63.2, 37.7, 36.1, 73.1, 43.6, 25.6, 59.1, 33.7, 33.4, 46.6, 92.2, 50.8, 54.6, 65.4, 45.3, 52.1, 58.0, 54.0, 48.8, 45.8, 32.0, 30.2, 34.9, 26.3, 20.5, 18.8, 18.8, 18.8, 18.8, 27.2, 18.2, 22.5, 5.9, 5.3, 16.0, 24.8, 40.8, 53.5, 49.5, 57.3, 49.3, 39.3, 70.1, 68.3, 73.4, 88.8, 65.5, 85.1, 68.2, 49.3, 46.3, 74.6, 57.9, 53.4, 41.7, 39.8, 53.8, 47.2, 44.3, 55.9, 25.6, 31.6, 41.3, 30.6, 34.3, 58.5, 29.3, 42.9, 63.3, 51.5, 75.1, 83.7, 75.5, 95.5, 61.4, 76.2, 92.6, 93.9, 81.3, 78.0, 96.0, 59.7, 68.0, 69.6, 77.5, 57.5, 67.3, 67.1, 62.7, 56.2, 56.6, 38.3, 46.0, 34.5, 31.9, 23.6, 22.8, 17.6, 16.4, 22.3, 9.1, 7.9, 5.6, 2.8, 7.8, 16.0, 29.8, 44.8, 47.8, 58.1, 50.1, 47.9, 86.2, 64.1, 76.0, 115.3, 78.8, 97.3, 116.9, 107.7, 87.3, 146.7, 95.3, 89.3, 123.6, 109.3, 72.2, 112.2, 68.2, 101.0, 111.0, 75.6, 58.5, 78.3, 45.1, 35.2, 22.4, 25.4, 25.2, 25.2, 27.2, 18.3, 34.4, 14.9, 11.3, 33.3, 8.1, 43.5, 63.2, 48.2, 66.5, 72.7, 64.0, 80.5, 57.4, 65.1, 86.2, 70.1, 68.1, 85.5, 101.9, 68.7, 78.6, 84.6, 69.2, 57.6, 66.7, 60.1, 43.1, 30.3, 26.0, 25.0, 34.0, 10.0, 35.0, 65.0\n",
      "test len: (141,)\n",
      "Seq_pred: (144,)\n",
      "\n",
      "\n",
      "MSE: 5607.753333333333, MAE: 61.74751773049644, MAPE: 503.4133172146274, R²: -0.7545148138640969\n",
      "\n",
      "\n",
      "dataset_name:  WineDataset\n",
      "Round:  1\n",
      "Test_lan: 31358.0, 31358.0 increasing to 34358.0, 34358.0 decreasing to 16695.0, 16695.0 increasing to 20624.0, 20624.0 decreasing to 19109.0, 19109.0 increasing to 22740.0, 22740.0 decreasing to 19010.0, 19010.0 increasing to 19270.0, 19270.0 increasing to 20933.0, 20933.0 increasing to 24257.0, 24257.0 increasing to 29161.0, 29161.0 decreasing to 28961.0, 28961.0 increasing to 36161.0, 36161.0 decreasing to 18615.0, 18615.0 increasing to 22583.0, 22583.0 increasing to 25383.0, 25383.0 decreasing to 22183.0, 22183.0 decreasing to 20338.0, 20338.0 increasing to 29161.0, 29161.0 decreasing to 26157.0\n",
      "test len: (36,)\n",
      "Seq_pred: (21,)\n",
      "Not enough sequences for prediction\n",
      "\n",
      "\n",
      "MSE: 0.0, MAE: 0.0, MAPE: 0.0, R²: 0.0\n",
      "\n",
      "\n",
      "-------------------------New Model\n"
     ]
    }
   ],
   "source": [
    "out = {}\n",
    "datasets = get_datasets()\n",
    "num_samples = 1\n",
    "\n",
    "for model in model_names:  # GPT-4 takes a about a minute to run\n",
    "    print(\"Model name: \", model)\n",
    "    steps = 500  # predict steps\n",
    "    for dataset_name in datasets_list:\n",
    "        mse_amount = 0.0\n",
    "        mae_amount = 0.0\n",
    "        mape_amount = 0.0\n",
    "        rsquare_amount = 0.0\n",
    "        print(\"dataset_name: \", dataset_name)\n",
    "        for i in range(num_samples):\n",
    "            print(\"Round: \", i+1)\n",
    "            desp = paraphrase_initial(dataset_name)\n",
    "            data = datasets[dataset_name]\n",
    "            train, test = data\n",
    "            Train_lan = paraphrase_seq2lan(train, desp)\n",
    "            Test_lan = paraphrase_seq2lan(test, desp)\n",
    "            seq_test = recover_lan2seq(Test_lan)\n",
    "            seq_pred = paraphrasing_predict_llm(desp, Train_lan, steps, model)\n",
    "\n",
    "            print(\"test len:\", test.shape)\n",
    "            print(\"Seq_pred:\", seq_pred.shape)\n",
    "            if seq_pred.shape >= test.shape:\n",
    "                seq_pred = seq_pred[:len(test)]\n",
    "            else:\n",
    "                print(\"Not enough sequences for prediction\")\n",
    "                break\n",
    "            mse = mean_squared_error(test, seq_pred)\n",
    "            mae = mean_absolute_error(test, seq_pred)\n",
    "            mape = metrics.mean_absolute_percentage_error(test, seq_pred)*100\n",
    "            r2 = r2_score(test, seq_pred)\n",
    "\n",
    "            mse_amount += mse\n",
    "            mae_amount += mae\n",
    "            mape_amount += mape\n",
    "            rsquare_amount += r2\n",
    "\n",
    "        mse_mean = mse_amount/num_samples\n",
    "        mae_mean = mae_amount/num_samples\n",
    "        mape_mean = mape_amount/num_samples\n",
    "        r2_mean = rsquare_amount/num_samples\n",
    "    \n",
    "        # print and plot values\n",
    "        print(\"\\n\")\n",
    "        print(f'MSE: {mse_mean}, MAE: {mae_mean}, MAPE: {mape_mean}, R²: {r2_mean}')\n",
    "        print(\"\\n\")\n",
    "    print('-------------------------New Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05ecc5c3f2ed3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:19:17.128184200Z",
     "start_time": "2024-02-16T06:19:17.094185700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "1937-01-01    132.5\n",
       "1937-05-01    116.7\n",
       "1937-09-01    100.7\n",
       "1938-01-01     98.4\n",
       "1938-05-01    127.4\n",
       "              ...  \n",
       "1982-05-01     82.2\n",
       "1982-09-01    118.8\n",
       "1983-01-01     84.3\n",
       "1983-05-01     99.2\n",
       "1983-09-01     50.3\n",
       "Freq: 4MS, Name: Sunspots, Length: 141, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets[\"SunspotsDataset\"]\n",
    "train, test = data\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T00:40:17.064325900Z",
     "start_time": "2024-02-16T00:40:14.724006900Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  LLMTime GPT-4\n",
      "Round:  1\n",
      "dataset_name:  SunspotsDataset\n",
      "test len: (141,)\n",
      "seq test len: (141,)\n",
      "LLMTime GPT-4\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "invalid model ID",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# if model == 'llama2-13b-chat':\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#     seq_pred = paraphrasing_predict_llama(desp, Train_lan, steps, model)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m---> 29\u001b[0m seq_pred \u001b[38;5;241m=\u001b[39m \u001b[43mparaphrasing_predict_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrain_lan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m, seq_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq_test:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, seq_test)\n",
      "File \u001b[1;32mD:\\Desktop\\llmtime-main(1)\\llmtime-main\\utils_paragraph.py:202\u001b[0m, in \u001b[0;36mparaphrasing_predict_llm\u001b[1;34m(desp, train_lan, steps, model_name)\u001b[0m\n\u001b[0;32m    199\u001b[0m prompt_add \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease predict ahead in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m steps, one step means (from 1.0 increasing to 2.0,) or\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    200\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(from 2.0 decreasing to 0.5,), The final output follows exactly steps. Sequence:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m content_train \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m desp \u001b[38;5;241m+\u001b[39m prompt_add \u001b[38;5;241m+\u001b[39m train_lan\n\u001b[1;32m--> 202\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_parameters_message\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_train\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m Test_lan \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest_lan:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Test_lan)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtime\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtime\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtime\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtime\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llmtime\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: invalid model ID"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b450346676930a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# MSE: 61944544.54545455, MAE: 6723.454545454545, MAPE: 26.215040829839143, R²: -1.187064640514277  original\n",
    "# MSE: 32630963.166666668, MAE: 5567.5, MAPE: 22.579059288746038, R²: 0.2894290524452805\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d627fa33c4d51d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T07:41:29.134743400Z",
     "start_time": "2024-02-15T07:41:29.099742100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (308777953.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    seq test\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
